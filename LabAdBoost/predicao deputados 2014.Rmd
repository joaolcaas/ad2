---
title: "Predicao Deputados"
author: "João Lucas"
date: "26 de fevereiro de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(ggplot2)
library(leaps)
library(caret)
library(plotly)
#library(C50)
library(rpart)
library(rpart.plot)
library(ROSE)
```

```{r}
#para lcc
df <- read.csv("/home/joaolaf/Área de Trabalho/train.csv",encoding = "utf-8")

#para notebook
#df <- read.csv("C:\\Users\\João Lucas\\Desktop\\train.csv")
colnames(df)[13] <- "recursos_pessoas_fisicas"
```


##separar dados de treino e teste

```{r}
dataPartition <- createDataPartition(y = df$situacao_final,p = 0.75,list = FALSE)

treino <- df[dataPartition,]
teste <- df[-dataPartition,]

```

##onde vamos plotar o grafico

<h3>1.Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? </h3>
```{r}
a <-treino %>% group_by(situacao_final) %>% 
  summarise(totalAparece = n())

a$indexS <- factor(a$situacao_final, levels = a$situacao_final)

p <- plot_ly(a,x =~indexS,y = ~totalAparece,type = 'bar', name = 'Situações') %>% layout(title = 'Frequência de cada situação',xaxis = list(title=""),yaxis = list(title = "Quantas vezes cada situação aparece"),barmode = 'stack')

p
```
##podemos falar que, como mostra os dados do treino, os resultados poderiam ser totalmente inviezados
##para mudar esses dados, vamos usar o under-simpling

##dados que vou usar para plotar os dados
```{r}
treino_balanced <- ovun.sample(situacao_final~., data=treino,p=0.5, seed=1,method="both")$data

table(treino_balanced$situacao_final)

```

```{r}
b <-treino_balanced %>% group_by(situacao_final) %>% 
  summarise(totalApareceBalanced = n())

b$indexS <- factor(b$situacao_final, levels = b$situacao_final)

p_balanced <- plot_ly(b,x =~indexS,y = ~totalApareceBalanced,type = 'bar', name = 'Situações') %>% layout(title = 'Frequência de cada situação',xaxis = list(title=""),yaxis = list(title = "Quantas vezes cada situação aparece"),barmode = 'stack')

p_balanced

```

<h3>2.Treine: um modelo de regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.</h3>



Para a nossa fórmula, iremos usar os dados que tiveram melhor eficácia quando tentamos predizer o número de votos (lab 3 da disciplina de ad2 -> https://rpubs.com/joaolcaas/predicao_2014_ad2)

```{r}
ctrl <- trainControl(method = "repeatedcv", 
                     number = 10, 
                     repeats = 10, 
                     verboseIter = FALSE)

formula.votos = as.formula(situacao_final ~  total_receita + total_despesa + quantidade_despesas + recursos_de_pessoas_juridicas + recursos_de_partidos + quantidade_doacoes + quantidade_fornecedores + media_receita + quantidade_doadores)
```


Para testar a nossa fórmula, vamos usar a regressão logística.(FALAR SOBRE A REGRESSÃO)

```{r}
regressaoLogistica <- train(formula.votos,
                 data = treino_balanced,
                 method="glm",
                 trControl = ctrl, 
                 family="binomial",      # se a variável for binária
                 na.action = na.omit)

regressaoLogistica

varImp(regressaoLogistica)

```

Pela nossa regressão logistica, vimos que os dados mais altos na votacao(como total_receita, que tinha 100 de importancia) desceram bastante e não são mais o mesmo.Além disso podemos ver o valor da Acurácia, que é de 0.8841712. Essa é uma métrica importante quando estamos falando sobre regressão logística(FALAR SOBRE ACURÁCIA). 

Vamos usar outra formula, adicionando novos atributos, deixando apenas as variáveis mais importantes segundo a regressão logistica

```{r}

formula.situacao.final = as.formula(situacao_final ~ media_receita + quantidade_doacoes + recursos_de_partidos + descricao_cor_raca + despesa_max_campanha + sexo + grau)


regressaoLogisticaNovaFormula <- train(formula.situacao.final,
                 data = treino_balanced,
                 method="glm",
                 trControl = ctrl, 
                 family="binomial",      # se a variável for binária
                 na.action = na.omit)

regressaoLogisticaNovaFormula

```
Para a nova fórmula, vemos que a Acurácia teve uma pequena melhora, mesmo estando com 7 preditores.

##arvore de decisão

```{r}
control <- rpart.control(maxdepth=20,minsplit=20,cp=0.001)
  
arvore <- rpart(formula.situacao.final, data = treino_balanced, control = control)
prp(arvore)

```


```{r}

arvore1 <- train(formula.situacao.final,
                data= treino_balanced, method = "rpart",
                trControl = ctrl,
                cp=0.001,  # parâmetro de complexidade
                maxdepth=20)
arvore1
```

Como o algoritmo seleciona a melhor Acurácia, o valor do cp retornado é de cp = 0.03765972, que vai nos levar a uma acurácia de 0.8869805, sendo um pouco menor do que a da regressão logística (aproximadamente 0.89). Isso pode ter se dado ao fato de que temos duas variáveis a menos aqui, em relação a fórmula da regressão logística. 

##usando adboost

Para o AdaBoost, vamos usar a fórmula que melhor se expressou na refressão logistica
```{r}
modelo <- train(formula.situacao.final,
                data=treino_balanced,
                trControl = ctrl,
                method = "adaboost")

modelo
```

<h3>3.Reporte acurácia, precision, recall e f-measure no treino e validação. Como você avalia os resultados? Justifique sua resposta.</h3>



<h3>4.Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo? Crie pelo menos um novo atributo que não está nos dados originais e estude o impacto desse atributo</h3>  
  